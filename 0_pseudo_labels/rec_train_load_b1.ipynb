{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 14:06:44.771540: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-14 14:06:44.771565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-14 14:06:44.772270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-14 14:06:44.777334: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-14 14:06:45.370836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from memory_profiler import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels', '/home/jczars/anaconda3/envs/tf/lib/python310.zip', '/home/jczars/anaconda3/envs/tf/lib/python3.10', '/home/jczars/anaconda3/envs/tf/lib/python3.10/lib-dynload', '', '/home/jczars/.local/lib/python3.10/site-packages', '/home/jczars/anaconda3/envs/tf/lib/python3.10/site-packages', '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jczars/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/jczars/4C22F02A22F01B22/Pollen_classification_view/')\n",
    "print(sys.path)\n",
    "from models.models_train import run_train\n",
    "from models.models_pre import  hyper_model_up\n",
    "from models.get_data import reload_data_train, splitData, load_data_labels  \n",
    "from models import utils\n",
    "from models import maneger_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir=\"/media/jczars/4C22F02A22F01B22/Pollen_classification_view/\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def prepare_data(conf, root_path):\n",
    "    \"\"\"\n",
    "    Prepares the environment for the pollen classification experiment.\n",
    "\n",
    "    Parameters:\n",
    "        conf (dict): Configuration dictionary containing:\n",
    "            - id_test (str): Test identifier.\n",
    "            - model (str): Model name to be used.\n",
    "            - aug (str): Data augmentation method.\n",
    "            - base (str): Base folder name of the dataset.\n",
    "            - path_base (str): Path to the base dataset folder.\n",
    "        root_path (str): Path to the root directory for results.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with paths and experiment information.\n",
    "    \"\"\"\n",
    "    # Destructuring the configuration dictionary for clarity\n",
    "    id_test = int(conf['id_test'])\n",
    "    model = conf['model']\n",
    "    aug = conf['aug']\n",
    "    base = conf['base']\n",
    "    base_path = conf['path_base']\n",
    "\n",
    "    # Label directory path\n",
    "    labels_dir = os.path.join(base_path, \"labels\")\n",
    "    categories = sorted(os.listdir(labels_dir))\n",
    "\n",
    "    # Experiment name and path\n",
    "    experiment_name = f\"{id_test}_{model}_{aug}_{base}\"\n",
    "    experiment_path = os.path.join(root_path, experiment_name)\n",
    "    pseudo_csv_dir = os.path.join(experiment_path, 'pseudo_csv')\n",
    "\n",
    "    # Creating the necessary folders in a more concise way\n",
    "    for directory in [root_path, experiment_path, pseudo_csv_dir]:\n",
    "        utils.create_folders(directory, flag=0)\n",
    "\n",
    "    print(f\"Training save directory: {experiment_path}, ID: {experiment_name}\")\n",
    "    \n",
    "    # Path to CSV file\n",
    "    csv_file_path = os.path.join(base_path, f\"{base}.csv\")\n",
    "    print('CSV data path:', csv_file_path)\n",
    "    \n",
    "    # Creating the labeled dataset\n",
    "    labeled_data = utils.create_dataSet(labels_dir, csv_file_path, categories)\n",
    "    \n",
    "    num_labels = len(labeled_data)\n",
    "    print('Total labeled data count:', num_labels)\n",
    "    \n",
    "    # Splitting data into training, validation and testing\n",
    "    train_path, val_path, test_path = splitData(labeled_data, root_path, base)\n",
    "\n",
    "    print(\"Finished preparing data\")\n",
    "\n",
    "    return {\n",
    "        'path_train': train_path,\n",
    "        'path_val': val_path,\n",
    "        'path_test': test_path,\n",
    "        'save_dir_train': experiment_path,\n",
    "        'pseudo_csv': pseudo_csv_dir,\n",
    "        'size_of_labels': num_labels,\n",
    "        'categories': categories\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build_train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def build_train_config(row, res_pre, time_step):\n",
    "    \"\"\"Build a configuration dictionary for model training.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        A row from the configuration DataFrame, containing model parameters.\n",
    "    res_pre : dict\n",
    "        A dictionary containing the result of the previous step, including labeled data paths.\n",
    "    iteration_num : int\n",
    "        The current iteration number in the training loop.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    config : dict\n",
    "        A dictionary containing the configuration for model training.\n",
    "    \"\"\"\n",
    "    # Extract directories from res_pre\n",
    "    save_dir_train = res_pre[\"save_dir_train\"]\n",
    "    test_path = res_pre[\"path_test\"]\n",
    "    categories = res_pre[\"categories\"]\n",
    "\n",
    "    # Path where the models will be saved\n",
    "    save_dir = os.path.join(save_dir_train, \"models\")\n",
    "\n",
    "    # Create the training configuration dictionary\n",
    "\n",
    "    config = {\n",
    "        \"model\": row[\"model\"],\n",
    "        \"id_test\": row[\"id_test\"],\n",
    "        \"data_path\": row[\"path_base\"],\n",
    "        \"test_path\": test_path,\n",
    "        \"batch_size\": row[\"batch_size\"],\n",
    "        \"img_size\": row[\"img_size\"],\n",
    "        \"num_classes\": len(categories),\n",
    "        \"split_valid\": row[\"split_valid\"],\n",
    "        \"last_activation\": row[\"last_activation\"],\n",
    "        \"save_dir\": save_dir,\n",
    "        \"learning_rate\": row[\"learning_rate\"],\n",
    "        \"optimizer\": row[\"optimizer\"],\n",
    "        \"epochs\": row[\"epochs\"],\n",
    "        \"freeze\": row[\"freeze\"],\n",
    "        \"time_step\": time_step,\n",
    "    }\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "def train_model(config, train_data, val_data, time_step):\n",
    "    \"\"\"\n",
    "    Train a model with the given configuration and data. If time_step > 0, it will load a pre-trained model\n",
    "    and continue training. Otherwise, it will train a new model from scratch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict\n",
    "        A dictionary containing the class_class_class_class_class_class_class_configuration for model training.\n",
    "    train_data : tuple\n",
    "        A tuple containing the training data and labels.\n",
    "    val_data : tuple\n",
    "        A tuple containing the validation data and labels.\n",
    "    time_step : int\n",
    "        The current training step. If time_step > 0, it will load a model from the previous step.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model_inst : keras.Model\n",
    "        The trained or reloaded model instance.\n",
    "    res_train : dict\n",
    "        A dictionary containing the training history and metrics.\n",
    "    \"\"\"\n",
    "    print('\\n[INFO]--> time_step ', time_step)\n",
    "    \n",
    "    # Reset model_inst to ensure it starts fresh for each time step\n",
    "    model_inst = None\n",
    "    \n",
    "    # If time_step > 0, try to load the model from a previous step, otherwise train a new model\n",
    "    if time_step > 0:\n",
    "        # Build the model path for the previous step\n",
    "        model_name = f\"{config['id_test']}_{config['model']}_bestLoss_{time_step - 1}.keras\"\n",
    "        save_path = os.path.join(config['save_dir'], model_name)\n",
    "        \n",
    "        # Load the model from the previous time step\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"[INFO]--> Loading model from {save_path}\")\n",
    "            model_inst = tf.keras.models.load_model(save_path)\n",
    "            \n",
    "            # Explicitly freeze the layers again\n",
    "            for layer in model_inst.layers:\n",
    "                layer.trainable = False  # Freeze all layers\n",
    "            \n",
    "            # Optionally unfreeze the last few layers if needed (based on config['freeze'])\n",
    "            for i, layer in enumerate(model_inst.layers):\n",
    "                if i >= config['freeze']:\n",
    "                    layer.trainable = True  # Unfreeze layers after the specified freeze index\n",
    "            \n",
    "            print(f\"[INFO]--> Model layers frozen up to layer {config['freeze']}\")\n",
    "        else:\n",
    "            raise ValueError(f\"[ERROR]--> Model from time_step {time_step - 1} not found at {save_path}\")\n",
    "    \n",
    "    # else:\n",
    "    #     # Instantiate the model from scratch for time_step == 0\n",
    "    #     print(\"[INFO]--> Training a new model from scratch...\")\n",
    "    #     model_inst = models_pre.hyper_model_up(config, verbose=1)\n",
    "    \n",
    "    # Train the model with the training and validation data\n",
    "    res_train = run_train(train_data, val_data, model_inst, config)\n",
    "    \n",
    "    # Save the model at the current time step\n",
    "    model_name = f\"{config['id_test']}_{config['model']}_bestLoss_{time_step}.keras\"\n",
    "    save_path = os.path.join(config['save_dir'], model_name)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_inst.save(save_path)\n",
    "    print(f\"[INFO]--> Model saved at {save_path}\")\n",
    "    \n",
    "    return model_inst, res_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def select(conf, data_uns_ini, _tempo):\n",
    "    \"\"\"\n",
    "    Selects pseudo-labels from classified unlabeled data.\n",
    "\n",
    "    Steps performed:\n",
    "    1. Rename paths in the classified data.\n",
    "    2. Filter the classified data by confidence level.\n",
    "    3. Select pseudo-labels and exclude them from the original unlabeled dataset.\n",
    "    4. Combine the previous training set with the selected pseudo-labels.\n",
    "    5. Save the new training and unlabeled datasets.\n",
    "\n",
    "    Parameters:\n",
    "        conf (dict): Configuration settings for selection.\n",
    "        data_uns_ini (DataFrame): Initial classified unlabeled data.\n",
    "        _pseudo_csv (str): Path to save pseudo-labels.\n",
    "        _tempo (int): Current iteration time.\n",
    "        train_data_csv (DataFrame): Previous training dataset.\n",
    "        limiar (float): Confidence threshold for selection.\n",
    "\n",
    "    Returns:\n",
    "        dict: Sizes of datasets and paths of new training set, or False if no labels selected.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Rename paths\n",
    "    \n",
    "    utils.renomear_path(conf, data_uns_ini)\n",
    "    print(\"Initial Data Preview:\", data_uns_ini.head())\n",
    "\n",
    "    # Step 2: Filter by confidence level\n",
    "    data_uns_fil = data_uns_ini[data_uns_ini['confidence'] > conf['limiar']]\n",
    "    print(f'Filtered data size: {len(data_uns_fil)}')\n",
    "\n",
    "    if data_uns_fil.empty:\n",
    "        print('No pseudo-labels passed the confidence filter.')\n",
    "        return False\n",
    "\n",
    "    # Step 3: Exclude selected labels from the unlabeled dataset\n",
    "    data_uns_ini = data_uns_ini[~data_uns_ini['file'].isin(data_uns_fil['file'])]\n",
    "    print(f'Remaining unlabeled data size: {len(data_uns_ini)}')\n",
    "\n",
    "    # Save the remaining unlabeled data\n",
    "    tempo_px = _tempo + 1\n",
    "    _csv_unlabels_t = os.path.join(conf['pseudo_csv'], f'unlabelSet_T{tempo_px}.csv')\n",
    "    print(f'Saving remaining unlabeled data to {_csv_unlabels_t}')\n",
    "    data_uns_ini.to_csv(_csv_unlabels_t, index=False)\n",
    "\n",
    "    # Step 4: Combine with previous training set\n",
    "    \n",
    "    train_data_csv = pd.read_csv(conf['path_train'])\n",
    "    \n",
    "    if _tempo == 0:\n",
    "        New_train_data = pd.concat([train_data_csv, data_uns_fil], ignore_index=True)\n",
    "    else:\n",
    "        previous_train_path = os.path.join(conf['pseudo_csv'], f'trainSet_T{_tempo}.csv')\n",
    "        train_data_csv = pd.read_csv(previous_train_path)\n",
    "        New_train_data = pd.concat([train_data_csv, data_uns_fil], ignore_index=True)\n",
    "\n",
    "    # Save the new training set\n",
    "    _csv_New_TrainSet = os.path.join(conf['pseudo_csv'], f'trainSet_T{tempo_px}.csv')\n",
    "    print(f'Saving new training set to {_csv_New_TrainSet}')\n",
    "    New_train_data.to_csv(_csv_New_TrainSet, index=False)\n",
    "\n",
    "    # Return summary of selections and data sizes\n",
    "    return {\n",
    "        'ini': len(data_uns_ini) + len(data_uns_fil),\n",
    "        'select': len(data_uns_fil),\n",
    "        'rest': len(data_uns_ini),\n",
    "        'train': len(train_data_csv),\n",
    "        'new_train': len(New_train_data),\n",
    "        '_csv_New_TrainSet': _csv_New_TrainSet\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def selection(pseudos_df, conf, _tempo, verbose=0):\n",
    "    \"\"\"\n",
    "    Performs selection of pseudo-labels for training if unlabeled data is available.\n",
    "\n",
    "    Steps:\n",
    "    1. Checks if there is any unlabeled data.\n",
    "    2. Calls the `selec` function to select pseudo-labels based on a confidence threshold.\n",
    "    3. Returns a dictionary with paths and sizes of datasets if selection is successful.\n",
    "    4. Returns None if no selection could be made or if there is no unlabeled data.\n",
    "\n",
    "    Parameters:\n",
    "        pseudos_df (DataFrame): Unlabeled data to be processed.\n",
    "        conf (dict): Configuration dictionary with paths and threshold settings.\n",
    "        res_pre (dict): Contains the path for saving pseudo-labels.\n",
    "        _tempo (int): Current time or iteration index.\n",
    "        training_data (Any): Training data used for comparison or updating with pseudo-labels.\n",
    "        verbose (int, optional): Verbosity level for printing messages. Default is 0 (no output).\n",
    "\n",
    "    Returns:\n",
    "        dict or None: Returns a dictionary with new data paths and dataset sizes if successful; \n",
    "                      returns None if no selection was made or no unlabeled data.\n",
    "    \"\"\"\n",
    "    if not pseudos_df.empty:\n",
    "        if verbose > 0:\n",
    "            print('\\n[STEP 2].4 - Selection')\n",
    "\n",
    "        # Perform pseudo-label selection\n",
    "        res_sel = select(\n",
    "            conf,\n",
    "            pseudos_df,\n",
    "            _tempo, \n",
    "        )\n",
    "\n",
    "        if res_sel:\n",
    "            # Return paths and dataset sizes for further processing\n",
    "            return {\n",
    "                'path_test': conf['path_test'],\n",
    "                'save_dir_train': conf.get('path_model', ''),  # Assuming model save path in config\n",
    "                'pseudo_csv': conf['pseudo_csv'],\n",
    "                '_csv_New_TrainSet': res_sel['_csv_New_TrainSet'],\n",
    "                'ini': res_sel['ini'],\n",
    "                'select': res_sel['select'],\n",
    "                'rest': res_sel['rest'],\n",
    "                'train': res_sel['train'],\n",
    "                'new_train': res_sel['new_train']\n",
    "            }\n",
    "        else:\n",
    "            # No valid pseudo-labels selected\n",
    "            if verbose > 0:\n",
    "                print(\"[INFO] No valid pseudo-labels were selected.\")\n",
    "            return None\n",
    "    else:\n",
    "        # No unlabeled data to process\n",
    "        if verbose > 0:\n",
    "            print(\"[INFO] No unlabeled data available for processing.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.get_data import load_unlabels, load_data_test\n",
    "from models.reports_build import predict_unlabeled_data\n",
    "\n",
    "def classification(class_config, model, _tempo, verbose=0):\n",
    "    \"\"\"\n",
    "    Classifies unlabeled images and generates pseudo-labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    class_config : dict\n",
    "        Configuration dictionary containing:\n",
    "            - 'path_base' (str): Base directory containing the images.\n",
    "            - 'batch_size' (int): Batch size for data loading.\n",
    "            - 'img_size' (tuple): Image size as (height, width).\n",
    "    res_pre : dict\n",
    "        Dictionary containing previous results and settings, including:\n",
    "            - 'categories' (list): List of class categories.\n",
    "            - 'pseudo_csv' (str): Directory path to save/load pseudo-labeled CSV files.\n",
    "    model : torch.nn.Module\n",
    "        The trained model used for making predictions.\n",
    "    _tempo : int\n",
    "        Current iteration of the pseudo-labeling process.\n",
    "    verbose : int, optional\n",
    "        Verbosity level (default is 0, no output). \n",
    "        Use higher values for more detailed output.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or None\n",
    "        DataFrame containing pseudo-label predictions if successful, or None if no data is available.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The function handles two scenarios:\n",
    "        1. If `_tempo` is 0, it loads unlabeled images directly from the specified directory.\n",
    "        2. If `_tempo` > 0, it loads pseudo-labels from a previously saved CSV file.\n",
    "    \n",
    "    Any errors encountered during file loading or data processing will be handled gracefully.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract parameters from config and res_pre dictionaries\n",
    "    unlabels_path = os.path.join(class_config['path_base'], 'images_unlabels')\n",
    "    batch_size = class_config['batch_size']\n",
    "    img_size = class_config['img_size']\n",
    "    categories = class_config['categories']\n",
    "    pseudo_csv_dir = class_config['pseudo_csv']\n",
    "\n",
    "    # Parameters for loading data\n",
    "    params = {\n",
    "        'unlabels': unlabels_path,\n",
    "        'img_size': img_size,\n",
    "        'batch_size': batch_size,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "    # Load unlabeled data or read CSV with previous pseudo-labels\n",
    "    if _tempo == 0:\n",
    "        if verbose:\n",
    "            print(f\"[INFO] Loading unlabeled images from: {unlabels_path}\")\n",
    "        unlabels_generator = load_unlabels(params)\n",
    "    else:\n",
    "        # Construct the path for the CSV file containing pseudo-labels\n",
    "        unlabels_csv_path = os.path.join(pseudo_csv_dir, f'unlabelSet_T{_tempo}.csv')\n",
    "        if verbose:\n",
    "            print(f\"[INFO] Loading pseudo-labels from CSV: {unlabels_csv_path}\")\n",
    "        \n",
    "        # Attempt to read the CSV with error handling\n",
    "        try:\n",
    "            df_unlabels = pd.read_csv(unlabels_csv_path)\n",
    "            if df_unlabels.empty:\n",
    "                if verbose:\n",
    "                    print(f\"[WARNING] No data found in CSV {unlabels_csv_path}\")\n",
    "                return None\n",
    "            if verbose:\n",
    "                print(\"[DEBUG] Head of the pseudo-labels DataFrame:\")\n",
    "                print(df_unlabels.head())\n",
    "            \n",
    "            # Load data generator from the DataFrame\n",
    "            unlabels_generator = load_data_test(df_unlabels, input_size=(img_size, img_size))\n",
    "        except FileNotFoundError:\n",
    "            if verbose:\n",
    "                print(f\"[ERROR] File not found: {unlabels_csv_path}\")\n",
    "            return None\n",
    "        except pd.errors.EmptyDataError:\n",
    "            if verbose:\n",
    "                print(f\"[ERROR] Empty data in CSV file: {unlabels_csv_path}\")\n",
    "            return None\n",
    "\n",
    "    # Perform predictions to generate pseudo-labels\n",
    "    if verbose:\n",
    "        print(\"[INFO] Performing pseudo-labeling on the unlabeled dataset\")\n",
    "    \n",
    "    pseudos_df = predict_unlabeled_data(\n",
    "        unlabels_generator, model, batch_size, categories, verbose=verbose\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[INFO] Total pseudo-labels generated: {len(pseudos_df)}\")\n",
    "\n",
    "    return pseudos_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def build_reports_config(time_step, config, res_pre, model_inst, res_train, verbose=0):\n",
    "    \"\"\"\n",
    "    Generates evaluation reports for a model based on given configurations, test data, and training results.\n",
    "\n",
    "    Parameters:\n",
    "    - time_step (int/float): The time step or timestamp associated with the evaluation.\n",
    "    - config (dict): A dictionary containing model and report configuration parameters, such as image size and batch size.\n",
    "    - res_pre (dict): Contains preprocessing results, including the test data path and category information.\n",
    "    - model_inst: The trained model instance.\n",
    "    - res_train (dict): Contains training results, including training history.\n",
    "    - verbose (int, optional): Level of verbosity for printing messages. Default is 0 (no output).\n",
    "\n",
    "    Returns:\n",
    "    - report_metrics (Any): Generated metrics from the report generation process.\n",
    "\n",
    "    Function Workflow:\n",
    "    1. Conditionally prints log messages indicating the start of report generation based on verbosity level.\n",
    "    2. Loads test data from a specified path.\n",
    "    3. Prepares the input size for data processing.\n",
    "    4. Loads test data for evaluation.\n",
    "    5. Creates necessary directories for report storage.\n",
    "    6. Configures and generates reports using provided data and model.\n",
    "    \"\"\"\n",
    "    if verbose > 0:\n",
    "        print('\\nReports Generation')\n",
    "        print(f'\\n[INFO]--> Step 1.4 - Evaluation Time Step: {time_step}')\n",
    "    \n",
    "    # Load test data\n",
    "    test_data = pd.read_csv(res_pre['path_test'])\n",
    "    print(\"\\n[INFO]--> res_pre['path_test']\", res_pre['path_test'])\n",
    "    print('\\n[INFO]--> test_data.head()', test_data.head())\n",
    "\n",
    "    img_size = config['img_size']\n",
    "    input_size = (img_size, img_size)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(f'\\n[INFO]--> Input size: {input_size}')\n",
    "    \n",
    "    # Load processed test data\n",
    "    test = load_data_test(test_data, input_size)\n",
    "    categories = res_pre['categories']\n",
    "    \n",
    "    # Create report saving directory\n",
    "    save_dir = os.path.join(res_pre['save_dir'], 'reports')\n",
    "    utils.create_folders(save_dir, 0)\n",
    "    \n",
    "    # Configure report generation settings\n",
    "    reports_config = {\n",
    "        'save_dir': save_dir,\n",
    "        'time': time_step,\n",
    "        'batch_size': config['batch_size'],\n",
    "        'id_test': config['id_test'],\n",
    "        'model': config['model']\n",
    "    }\n",
    "    \n",
    "    # Generate reports\n",
    "    history = res_train['history']\n",
    "    report_metrics = reports_build.reports_gen(test, model_inst, categories, history, reports_config)\n",
    "    \n",
    "    return report_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def rel_data(time_step, report_metrics, res_train, res_sel, workbook_path, config_index, verbose=0):\n",
    "    \"\"\"\n",
    "    Saves data into an Excel workbook for reporting purposes.\n",
    "\n",
    "    Parameters:\n",
    "        time_step (str/int): Current time step or identifier for data logging.\n",
    "        report_metrics (dict): Metrics from the report generation process.\n",
    "        res_train (dict): Training result data, including timing and accuracy metrics.\n",
    "        res_sel (dict): Selection result data, containing training set sizes and other statistics.\n",
    "        workbook_path (str): Path to the Excel workbook.\n",
    "        config_index (str/int): Identifier for the configuration used.\n",
    "        verbose (int, optional): Verbosity level for printing messages. Default is 0 (no output).\n",
    "    \"\"\"\n",
    "    if verbose > 0:\n",
    "        print(\"\\n[INFO] Workbook name:\", workbook_path)\n",
    "    \n",
    "    try:\n",
    "        workbook = openpyxl.load_workbook(workbook_path)\n",
    "        if verbose > 0:\n",
    "            print(\"Sheets in workbook:\", workbook.sheetnames)\n",
    "    except FileNotFoundError:\n",
    "        if verbose > 0:\n",
    "            print(\"[ERROR] Workbook not found, creating a new one.\")\n",
    "        workbook = openpyxl.Workbook()\n",
    "\n",
    "    sheet_name = 'Table'\n",
    "    \n",
    "    # Check if the sheet already exists\n",
    "    if sheet_name in workbook.sheetnames:\n",
    "        if verbose > 0:\n",
    "            print(f'Sheet \"{sheet_name}\" exists.')\n",
    "        Met_page = workbook[sheet_name]  # Access the existing sheet\n",
    "    else:\n",
    "        if verbose > 0:\n",
    "            print(f'Creating new sheet: \"{sheet_name}\".')\n",
    "        Met_page = workbook.create_sheet(sheet_name)  # Create a new sheet\n",
    "        if verbose > 0:\n",
    "            print('[INFO] -rel_data- Saving test header.')\n",
    "        cols_exe = ['Tempo', 'test_loss', 'test_accuracy', 'precision', 'recall', 'fscore', \n",
    "                    'kappa', 'str_time', 'end_time', 'delay', 'best_epoch', \n",
    "                    'ini', 'select', 'rest', 'train', 'new_train', 'id_test']\n",
    "        Met_page.append(cols_exe)  # Add header row with column names\n",
    "    \n",
    "    # Append data to the sheet\n",
    "    data = [\n",
    "        str(time_step),\n",
    "        report_metrics.get('test_loss', ''),\n",
    "        report_metrics.get('test_accuracy', ''),\n",
    "        report_metrics.get('precision', ''),\n",
    "        report_metrics.get('recall', ''),\n",
    "        report_metrics.get('fscore', ''),\n",
    "        report_metrics.get('kappa', ''),\n",
    "        res_train.get('start_time', ''),\n",
    "        res_train.get('end_time', ''),\n",
    "        res_train.get('duration', ''),\n",
    "        res_train.get('best_epoch', ''),\n",
    "        res_sel.get('ini', ''),\n",
    "        res_sel.get('select', ''),\n",
    "        res_sel.get('rest', ''),\n",
    "        res_sel.get('train', ''),\n",
    "        res_sel.get('new_train', ''),\n",
    "        config_index\n",
    "    ]\n",
    "    Met_page.append(data)\n",
    "    \n",
    "    # Save the workbook\n",
    "    workbook.save(workbook_path)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(\"Data saved successfully. Sheets available:\", workbook.sheetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@profile\n",
    "def rel_data(time_step, report_metrics, res_train, res_sel, workbook_path, config_index, verbose=0):\n",
    "    \"\"\"\n",
    "    Saves data into an Excel workbook for reporting purposes.\n",
    "\n",
    "    Parameters:\n",
    "        time_step (str/int): Current time step or identifier for data logging.\n",
    "        report_metrics (dict): Metrics from the report generation process.\n",
    "        res_train (dict): Training result data, including timing and accuracy metrics.\n",
    "        res_sel (dict): Selection result data, containing training set sizes and other statistics.\n",
    "        workbook_path (str): Path to the Excel workbook.\n",
    "        config_index (str/int): Identifier for the configuration used.\n",
    "        verbose (int, optional): Verbosity level for printing messages. Default is 0 (no output).\n",
    "    \"\"\"\n",
    "    if verbose > 0:\n",
    "        print(\"\\n[INFO] Workbook name:\", workbook_path)\n",
    "    \n",
    "    try:\n",
    "        workbook = openpyxl.load_workbook(workbook_path)\n",
    "        if verbose > 0:\n",
    "            print(\"Sheets in workbook:\", workbook.sheetnames)\n",
    "    except FileNotFoundError:\n",
    "        if verbose > 0:\n",
    "            print(\"[ERROR] Workbook not found, creating a new one.\")\n",
    "        workbook = openpyxl.Workbook()\n",
    "\n",
    "    sheet_name = 'Table'\n",
    "    \n",
    "    # Check if the sheet already exists\n",
    "    if sheet_name in workbook.sheetnames:\n",
    "        if verbose > 0:\n",
    "            print(f'Sheet \"{sheet_name}\" exists.')\n",
    "        Met_page = workbook[sheet_name]  # Access the existing sheet\n",
    "    else:\n",
    "        if verbose > 0:\n",
    "            print(f'Creating new sheet: \"{sheet_name}\".')\n",
    "        Met_page = workbook.create_sheet(sheet_name)  # Create a new sheet\n",
    "        if verbose > 0:\n",
    "            print('[INFO] -rel_data- Saving test header.')\n",
    "        cols_exe = ['Tempo', 'test_loss', 'test_accuracy', 'precision', 'recall', 'fscore', \n",
    "                    'kappa', 'str_time', 'end_time', 'delay', 'best_epoch', \n",
    "                    'ini', 'select', 'rest', 'train', 'new_train', 'id_test']\n",
    "        Met_page.append(cols_exe)  # Add header row with column names\n",
    "    \n",
    "    # Append data to the sheet\n",
    "    data = [\n",
    "        str(time_step),\n",
    "        report_metrics.get('test_loss', ''),\n",
    "        report_metrics.get('test_accuracy', ''),\n",
    "        report_metrics.get('precision', ''),\n",
    "        report_metrics.get('recall', ''),\n",
    "        report_metrics.get('fscore', ''),\n",
    "        report_metrics.get('kappa', ''),\n",
    "        res_train.get('start_time', ''),\n",
    "        res_train.get('end_time', ''),\n",
    "        res_train.get('duration', ''),\n",
    "        res_train.get('best_epoch', ''),\n",
    "        res_sel.get('ini', ''),\n",
    "        res_sel.get('select', ''),\n",
    "        res_sel.get('rest', ''),\n",
    "        res_sel.get('train', ''),\n",
    "        res_sel.get('new_train', ''),\n",
    "        config_index\n",
    "    ]\n",
    "    Met_page.append(data)\n",
    "    \n",
    "    # Save the workbook\n",
    "    workbook.save(workbook_path)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print(\"Data saved successfully. Sheets available:\", workbook.sheetnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "def rec_id(workbook_path, id_test):\n",
    "    # Load configuration data from 'Sheet'\n",
    "    config_data = pd.read_excel(workbook_path, sheet_name=\"Sheet\")\n",
    "    config = config_data.loc[id_test]\n",
    "    rec_csv = pd.read_excel(workbook_path, sheet_name=\"Table\")\n",
    "    fil=rec_csv[rec_csv['id_test'] == id_test]\n",
    "    tempo_px=len(fil)\n",
    "\n",
    "    return config, tempo_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_class_config(config, model_inst, pseudo_csv, categories, tempo_px):\n",
    "    print('\\n[STEP] Classification phase')\n",
    "\n",
    "    class_config={'path_base': config['path_base'],\n",
    "                  'batch_size': config['batch_size'],\n",
    "                  'img_size': config['img_size'],\n",
    "                  'categories': categories,\n",
    "                  'pseudo_csv': pseudo_csv\n",
    "    }\n",
    "    return class_config    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(workbook_path, id_test):\n",
    "    print('\\n[STEP] Training phase')\n",
    "    %memit  config, tempo_px = rec_id(workbook_path, id_test)\n",
    "    print(\"\\nconfig\", config)\n",
    "    print(\"\\ntempo_px\", tempo_px) \n",
    "\n",
    "    # Label directory path\n",
    "    labels_dir = os.path.join(config['path_base'], \"labels\")\n",
    "    categories = sorted(os.listdir(labels_dir))\n",
    "\n",
    "    # recurarar csv_NewtainSet14\n",
    "    _pseudo_csv=f'{working_dir}/0_pseudo_labels/Reports/{id_test}_{config[\"model\"]}_{config[\"aug\"]}_{config[\"base\"]}/pseudo_csv/'\n",
    "    _csv_New_TrainSet = os.path.join(_pseudo_csv, f'trainSet_T{tempo_px}.csv')\n",
    "    print(_csv_New_TrainSet)\n",
    "\n",
    "    confi_load={\n",
    "        'aug': config['aug'],\n",
    "        'img_size': config['img_size'],\n",
    "    }\n",
    "\n",
    "    train, val = reload_data_train(confi_load, _csv_New_TrainSet)\n",
    "\n",
    "    save_dir = f'{working_dir}/0_pseudo_labels/Reports/{id_test}_{config[\"model\"]}_{config[\"aug\"]}_{config[\"base\"]}/models/'\n",
    "    print(f\"save_dir: {save_dir}\")\n",
    "\n",
    "    config_train={\n",
    "        'id_test': id_test,\n",
    "        'model': config['model'],\n",
    "        'save_dir': save_dir,\n",
    "        'freeze': config['freeze'],\n",
    "        'batch_size': config['batch_size'],\n",
    "        'epochs': config['epochs'],\n",
    "        }\n",
    "\n",
    "    %memit \n",
    "    model_inst, res_train = train_model(config_train, train, val, tempo_px)\n",
    "    \n",
    "    class_config=build_class_config(config, model_inst, _pseudo_csv, categories, tempo_px)\n",
    "\n",
    "    pseudos_df=classification(class_config, model_inst, tempo_px)\n",
    "    res_sel = selection(pseudos_df, config, tempo_px)\n",
    "\n",
    "    if res_sel is None:\n",
    "        if verbose > 0:\n",
    "            print(\"[INFO] No more unlabeled data to process.\")\n",
    "        #break\n",
    "\n",
    "    time_step=tempo_px\n",
    "    \"\"\"\n",
    "    #Test_path\n",
    "    test_path=f'{working_dir}/0_pseudo_labels/Reports/{config['base']}_testSet.csv'\n",
    "    report_metrics = build_reports_config(time_step, config, res_pre, model_inst, res_train)\n",
    "\n",
    "    config_rel={\n",
    "        'test_path': test_path,\n",
    "        'categories': categories,\n",
    "        \n",
    "    }\n",
    "\n",
    "    rel_data(time_step, report_metrics, res_train, res_sel, workbook_path, config_index, verbose=0)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(workbook_path, start_index, end_index=None, verbose=0):\n",
    "    if verbose > 0:\n",
    "        print(\"\\n[INFO] Workbook name:\", workbook_path)\n",
    "    \n",
    "    workbook = openpyxl.load_workbook(workbook_path)\n",
    "    if verbose > 0:\n",
    "        print(\"Sheets in workbook:\", workbook.sheetnames)\n",
    "\n",
    "    # Set root path\n",
    "    root_path = os.path.dirname(workbook_path)\n",
    "    \n",
    "    # Load configuration data from 'Sheet'\n",
    "    config_data = pd.read_excel(workbook_path, sheet_name=\"Sheet\")\n",
    "    \n",
    "    # Validate start_index\n",
    "    if start_index >= len(config_data):\n",
    "        if verbose > 0:\n",
    "            print(f\"[ERROR] start_index ({start_index}) is out of range.\")\n",
    "        return\n",
    "    if end_index is None:\n",
    "        end_index = len(config_data) - start_index\n",
    "\n",
    "    # Iterate over each row of configuration starting from `start_index`\n",
    "    for row_idx in range(end_index):\n",
    "\n",
    "        config_index = start_index + row_idx\n",
    "        config = config_data.loc[config_index]\n",
    "        if verbose > 0:\n",
    "            print(\"Current configuration:\", config)\n",
    "\n",
    "        # Initialize time control and unlabeled data flag\n",
    "        time_step = 0\n",
    "        has_unlabeled_data = True\n",
    "        res_pre = prepare_data(config, root_path)\n",
    "\n",
    "        conf_load = {\n",
    "            'path_train': res_pre['path_train'],\n",
    "            'path_val': res_pre['path_val'],\n",
    "            'img_size': config['img_size'],\n",
    "            'aug': config['aug']\n",
    "        }\n",
    "        if verbose > 0:\n",
    "            print(\"Loading data with config:\", conf_load)\n",
    "\n",
    "        train, val = load_data_labels(conf_load)\n",
    "        del conf_load\n",
    "\n",
    "        while has_unlabeled_data:\n",
    "            maneger_gpu.monitor_memory_and_run()\n",
    "\n",
    "            if verbose > 0:\n",
    "                print('\\n[STEP] Training phase')\n",
    "            conf_train = build_train_config(config, res_pre, time_step)\n",
    "            model_train, res_train = train_model(conf_train, train, val, time_step)\n",
    "            del conf_train\n",
    "            maneger_gpu.log_memory_usage('conf_train')\n",
    "\n",
    "            report_metrics = build_reports_config(time_step, config, res_pre, model_train, res_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file /tmp/ipykernel_89055/2659114944.py\n",
      "folders test already exists:  /media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0\n",
      "folders test already exists:  /media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/5_DenseNet201_sem_BI_5\n",
      "folders test already exists:  /media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/5_DenseNet201_sem_BI_5/pseudo_csv\n",
      "Training save directory: /media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/5_DenseNet201_sem_BI_5, ID: 5_DenseNet201_sem_BI_5\n",
      "CSV data path: BD/BI_5/BI_5.csv\n",
      "_path_data  BD/BI_5/labels\n",
      "_csv_data  BD/BI_5/BI_5.csv\n",
      "CATEGORIES:  ['equatorial_alongada', 'equatorial_circular', 'equatorial_eliptica', 'polar_circular', 'polar_triangular', 'polar_tricircular']\n",
      "BD/BI_5/BI_5.csv\n",
      "                     file\n",
      "labels                   \n",
      "equatorial_alongada    70\n",
      "equatorial_circular   231\n",
      "equatorial_eliptica    44\n",
      "polar_circular        150\n",
      "polar_triangular      105\n",
      "polar_tricircular      35\n",
      "Total labeled data count: 635\n",
      "\n",
      " Train split\n",
      "                     file\n",
      "labels                   \n",
      "equatorial_alongada    53\n",
      "equatorial_circular   138\n",
      "equatorial_eliptica    31\n",
      "polar_circular         91\n",
      "polar_triangular       71\n",
      "polar_tricircular      22\n",
      "\n",
      " Test split\n",
      "                     file\n",
      "labels                   \n",
      "equatorial_alongada    11\n",
      "equatorial_circular    51\n",
      "equatorial_eliptica     6\n",
      "polar_circular         36\n",
      "polar_triangular       17\n",
      "polar_tricircular       6\n",
      "\n",
      " Val split\n",
      "                     file\n",
      "labels                   \n",
      "equatorial_alongada     6\n",
      "equatorial_circular    42\n",
      "equatorial_eliptica     7\n",
      "polar_circular         23\n",
      "polar_triangular       17\n",
      "polar_tricircular       7\n",
      "Finished preparing data\n",
      "res_pre: {'path_train': '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/BI_5_trainSet.csv', 'path_val': '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/BI_5_valSet.csv', 'path_test': '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/BI_5_testSet.csv', 'save_dir_train': '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/5_DenseNet201_sem_BI_5', 'pseudo_csv': '/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/5_DenseNet201_sem_BI_5/pseudo_csv', 'size_of_labels': 635, 'categories': ['equatorial_alongada', 'equatorial_circular', 'equatorial_eliptica', 'polar_circular', 'polar_triangular', 'polar_tricircular']}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    workbook_path = \"/media/jczars/4C22F02A22F01B22/Pollen_classification_view/0_pseudo_labels/Reports0/config_pseudo_label_pre.xlsx\"\n",
    "    start_index = 5\n",
    "\n",
    "    #run(workbook_path, id_test)\n",
    "\n",
    "    res_pre=run(workbook_path, start_index, end_index=1, verbose=0)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
